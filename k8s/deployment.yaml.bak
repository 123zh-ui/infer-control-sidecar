apiVersion: apps/v1
kind: Deployment
metadata:
  name: wings-infer
  labels:
    app: wings-infer
spec:
  replicas: 1
  selector:
    matchLabels:
      app: wings-infer
  template:
    metadata:
      labels:
        app: wings-infer
    spec:
      # 共享卷配置
      volumes:
        - name: shared-volume
          emptyDir:
            medium: Memory  # 使用内存作为共享卷，提高性能
        - name: model-volume
          persistentVolumeClaim:
            claimName: model-pvc  # 模型数据持久化

      containers:
        # Wings-Infer 控制容器
        - name: wings-infer
          image: wings-infer:latest  # 替换为实际的镜像地址
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 9000
              name: http
          env:
            - name: ENGINE_TYPE
              value: "vllm"  # 可选: vllm 或 sglang
            - name: ENGINE_PORT
              value: "8000"
            - name: WINGS_PORT
              value: "9000"
            - name: MODEL_NAME
              value: "meta-llama/Llama-2-7b-chat-hf"
            - name: MODEL_PATH
              value: "/models"
            - name: TP_SIZE
              value: "1"
            - name: MAX_MODEL_LEN
              value: "4096"
          volumeMounts:
            - name: shared-volume
              mountPath: /shared-volume
            - name: model-volume
              mountPath: /models
              readOnly: true
          resources:
            requests:
              cpu: "500m"
              memory: "1Gi"
            limits:
              cpu: "2"
              memory: "4Gi"
          readinessProbe:
            httpGet:
              path: /health
              port: 9000
            initialDelaySeconds: 10
            periodSeconds: 10
          livenessProbe:
            httpGet:
              path: /health
              port: 9000
            initialDelaySeconds: 30
            periodSeconds: 30

        # 引擎容器 (vLLM)
        - name: vllm-engine
          image: vllm/vllm-openai:latest  # vLLM官方镜像
          imagePullPolicy: IfNotPresent
          command: ["/bin/sh", "-c"]
          args:
            - |
              # 等待wings-infer写入启动命令
              echo "Waiting for start command..."
              while [ ! -f /shared-volume/start_command.sh ]; do
                sleep 1
              done

              # 读取并执行启动命令
              echo "Start command found, executing..."
              cd /shared-volume
              bash start_command.sh

              # 写入运行状态
              echo "running" > /shared-volume/engine_status.txt

              # 保持容器运行
              echo "Engine started successfully"
              tail -f /dev/null
          volumeMounts:
            - name: shared-volume
              mountPath: /shared-volume
            - name: model-volume
              mountPath: /models
              readOnly: true
          resources:
            requests:
              cpu: "2"
              memory: "8Gi"
            limits:
              cpu: "8"
              memory: "32Gi"

---
# 模型持久化存储
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: model-pvc
spec:
  accessModes:
    - ReadOnlyMany
  resources:
    requests:
      storage: 50Gi  # 根据模型大小调整
  storageClassName: standard  # 根据集群配置调整